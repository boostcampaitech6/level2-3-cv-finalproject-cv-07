# êµ°ì¤‘ ê³„ìˆ˜(Crowd Counting) ëª¨ë¸ì˜ ê³„ì‚° íš¨ìœ¨ì„±ì„ ìœ„í•œ ê²½ëŸ‰ ëª¨ë¸ë§

<img width="450" src="https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-07/assets/83398511/585ff861-3771-42ee-b03d-0fccad6d2896">

ëª¨ë¸ë§ ëŒ€ìƒ
- Transformer ê¸°ë°˜ì˜ êµ°ì¤‘ ê³„ìˆ˜ SOTA ëª¨ë¸ì¸ PET(Point-Query Quadtree for Crowd Counting, Localization, and More)ëª¨ë¸

ë°ì´í„°ì…‹
- [ShanghaiTech A](https://paperswithcode.com/dataset/shanghaitech)
  
  <img width="398" alt="image" src="https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-07/assets/83398511/6c42593c-c7c4-4cb6-ab91-f6f44c55e8bc">


ì œê³µì‚¬í•­
- ë² ì´ìŠ¤ ë¼ì¸ìœ¼ë¡œì„œ í•™ìŠµëœ êµ°ì¤‘ ê³„ìˆ˜ ëª¨ë¸ê³¼ í•´ë‹¹ ëª¨ë¸ì„ í•™ìŠµ ì‹œí‚¨ ë°ì´í„° ì…‹ ì œê³µ
- ëª¨ë¸ ì •í™•ë„ ì¸¡ì •ì„ ìœ„í•œ ë„êµ¬ ì œê³µ
- ì¶”ë¡  ì†ë„ ì¸¡ì •ì„ ìœ„í•œ ë„êµ¬ ì œê³µ

ìˆ˜í–‰ì‚¬í•­
- ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ë ˆì´ì–´, í•©ì„±ê³± ë¸”ë¡ ë“±ì„ ìˆ˜ì •í•˜ì—¬ ë² ì´ìŠ¤ ë¼ì¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ CPU/GPUì—ì„œì˜ ì¶”ë¡  ì†ë„ ê°œì„ 

ì ‘ê·¼ë°©ë²• 
- ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì´ ì•„ë‹Œ ì£¼ì–´ì§„ ëª¨ë¸ì— ëŒ€í•œ êµ¬ì¡° ë³€ê²½ë§Œì„ í—ˆìš©í•¨


## ê¸°ê°„
24.02.26 ~ 24.03.27

## í”„ë¡œì íŠ¸ ëª©í‘œ
Transformer ê¸°ë°˜ì˜ êµ°ì¤‘ ê³„ìˆ˜ SOTA ëª¨ë¸ì¸ PET (Chengxin Liu et al., ICCV 2023)ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ë ˆì´ì–´/ë¸”ë¡ì„ ì¬ì„¤ê³„í•˜ì—¬ ëª¨ë¸ì˜ ì •í™•ë„(MAE(Mean Absolute Error))ì„ ìµœëŒ€í•œ ìœ ì§€í•˜ë©´ì„œë„, CPU/GPUì—ì„œì˜ ì¶”ë¡  ì†ë„ë¥¼ ê°œì„ 

## í”„ë¡œì íŠ¸ íŒ€ êµ¬ì„± ë° ì—­í• 

  |<a href="https://github.com/kimhankyu">ê¹€í•œê·œ </a>| <a href="https://github.com/haeun1">ë¯¼í•˜ì€ </a> | <a href="https://github.com/HayeonLee88">ì´í•˜ì—° </a> | <a href="https://github.com/DorianYellow"> ì‹¬ìœ ìŠ¹ </a>| <a href="https://github.com/chyeon01">ì•ˆì±„ì—° </a>| <a href="https://github.com/KANG-dg">ê°•ë™ê¸° </a>| 
  | :-: | :-: | :-: | :-: | :-: | :-: |
  | <img width="100" src="https://avatars.githubusercontent.com/u/32727723?v=4"> | <img width="100" src="https://avatars.githubusercontent.com/u/87661039?v=4"> | <img width="100" src="https://avatars.githubusercontent.com/u/83398511?v=4"> | <img width="100" src="https://avatars.githubusercontent.com/u/146207162?v=4"> | <img width="100" src="https://avatars.githubusercontent.com/u/86558738?v=4"> | <img width="100" src="https://avatars.githubusercontent.com/u/121837927?v=4"> |

- ê°•ë™ê¸°: backboneì˜ ì˜í–¥ì´ ë‚®ì€ layer êµ¬ì¡° ë³€ê²½, transformerì˜ encoder, decoderêµ¬ì¡° ê°œì„  (1x1convolution, batch norm, layerê°ì†Œ)
- ê¹€í•œê·œ: transformerì˜ encoder layer êµ¬ì¡° ê°œì„ (FastViT)
- ë¯¼í•˜ì€: vgg13_bn backbone êµì²´, transformerì˜ encoder layer êµ¬ì¡° ê°œì„ (poolformer)
- ì‹¬ìœ ìŠ¹: Encoder ë¸”ë¡ ì¬ì„¤ê³„ - ë¸”ë¡ê°œìˆ˜ ìµœì í™”, window size ìµœì í™”, FFN ì¡°ì •
- ì•ˆì±„ì—° : vgg11_bn backboneêµì²´, transformerì˜ encoder layer êµ¬ì¡° ê°œì„  (depthwise)
- ì´í•˜ì—°: mobilenet backbone êµì²´, encoder progressive window size ë³€ê²½, transformerì˜ encoder, decoder Parameters sharing, transformerì˜ encoder layer êµ¬ì¡° ê°œì„  (poolformer)



## ì„¤ì¹˜ ë° ì‹¤í–‰
```shell
git clone https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-07.git
cd level2-3-cv-finalproject-cv-07
mkdir data
# https://paperswithcode.com/dataset/shanghaitech - ShanghaiTech A ë°ì´í„° ë‹¤ìš´ë¡œë“œ í›„ data ë””ë ‰í† ë¦¬ì— ë„£ê¸°

pip install -r requirements.txt

# train ì‹œ
sh ./train.sh
# transformer ë‹¤ë¥¸ ë©”ì†Œë“œë¡œ ë³€ê²½ ì‹œ
# ./models/transformer/__init__.py ì— from .prog_win_transformer import build_encoder, build_decoder í•´ë‹¹ ë¶€ë¶„ ë³€ê²½

# eval ì‹œ
sh ./evel.sh

```
# ğŸ› ï¸Methodology

### Backbone ê²½ëŸ‰í™”

<img width="800" alt="Untitled" src="https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-07/assets/87661039/c6be21a0-2015-4cb0-b22b-616281284790">


- Backbone êµì²´: mobilenet_v3, vgg11_bn, vgg13_bn
- Backbone layer ì œê±°: ë¹„ì¤‘ì´ ë‚®ì€ Batchnorm layerë¥¼ ì„ ë³„, ì œê±°

### Encoder ê²½ëŸ‰í™”

1. PoolFormer
<img width="800" alt="image" src="https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-07/assets/83398511/34a2a9b9-3c3d-42c9-b47f-cf9f8505a04b">
    
- PETì˜ Encoderì— self attention ì—°ì‚°ì„ poolingìœ¼ë¡œ ëŒ€ì²´
- ì—°ì‚°ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚°, token mixer ì—­í•  ìˆ˜í–‰
- cross-channel poolingì„ ì‚¬ìš©í•´ ì—¬ëŸ¬ feature map ê°„ ì •ë³´ í†µí•©

2. Depthwise
    
<img width="800" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-03-27 á„‹á…©á„’á…® 12 30 54" src="https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-07/assets/87661039/a25b51e4-2eab-4dc1-8ae7-6542ad8b6d3b">
    
- Poolformer ì‚¬ìš© ì‹œ ì„±ëŠ¥ í•˜ë½ ë³´ì™„í•˜ê¸° ìœ„í•´ depthwise convolution ì‚¬ìš©
- ì§€ì—° ì‹œê°„ ì˜¤ë²„í—¤ë“œ ë„ì…í•˜ì§€ ì•Šìœ¼ë©´ì„œ ì„±ëŠ¥ í–¥ìƒ

3. Component ì¬ì„¤ê³„
    
<img width="600" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-03-27 á„‹á…©á„’á…® 12 39 12" src="https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-07/assets/87661039/ac66602d-e12d-47cc-9ae0-5ff01d389c35">
   
- encoder block ê°œìˆ˜ ìµœì í™”
- window size ìµœì í™”
- FFN ì¡°ì •

### Encoder, Decoder ê²½ëŸ‰í™”

<img width="400" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2024-03-27 á„‹á…©á„’á…® 12 33 55" src="https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-07/assets/87661039/a98863df-4192-4014-acb6-3946ebb07efb">


- encoder, decoderì˜ linear layer, layer norm ê°„ì†Œí™”
- Linear layerë¥¼ 1x1 convolutionìœ¼ë¡œ ëŒ€ì²´
- Feed froward network ì¡°ì •

### **TOP 3**

**Mae ì¸¡ë©´**

|  | ì‹¤í—˜ëª… | Best MAE | Inference time |
| --- | --- | --- | --- |
| encoder reduction | encoder layer X 2 + [(32,16),(8,4)] | ì•½ 6.22% ê°ì†Œ(50.49â†’47.35) | 6.92ms ê°ì†Œ(63.95â†’57.03) |
| poolformer | Enc win sizeÂ  1/4 + attnX2-> poolingX2 | ì•½ 0.30% ê°ì†Œ(50.13â†’49.98) | 5.6ms ê°ì†Œ(63.95â†’58.35) |
| depthwise | depthwise encoder layer 1ê°œ [(8,4)] | ì•½ 0.02% ì¦ê°€(52.39 â†’ 52.4) | 8.29ms ê°ì†Œ(65.62 â†’ 57.33) |

**Inference ì¸¡ë©´**

|  | ì‹¤í—˜ëª… | Best MAE | Inference time |
| --- | --- | --- | --- |
| encoder reduction | encoder layer X 2 + [(32,16),(8,4)]â€¢ ffn ì œê±° | ì•½ 1.78% ì¦ê°€Â (50.49â†’51.39) | 9.19ms ê°ì†ŒÂ (63.95â†’54.76) |
| poolformer | layer reduction + pooling(X2) [(32,16),(8,4)] | ì•½ 6.98% ì¦ê°€ (50.13â†’53.63) | 6.98ms ê°ì†ŒÂ (63.95â†’56.97) |
| depthwise | depthX1_attnX1 | ì•½ 2.04% ì¦ê°€Â (52.39 â†’ 53.46) | 9.27ms ê°ì†ŒÂ (63.95 â†’ 54.68) |

### ìµœì¢… ëª¨ë¸

![pet_A](https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-07/assets/83398511/e66fccce-fcd4-4708-843a-e4b0da9b6ca7)
![our_model](https://github.com/boostcampaitech6/level2-3-cv-finalproject-cv-07/assets/83398511/4c3bf7d0-1f02-4a5d-8d8e-59d6886dac32)


1. encoder layerë¥¼ 4ê°œì—ì„œ 2ê°œë¡œ ê°ì†Œ
2. Encoder window sizeë¥¼ [(32,16),(16,8)] ì—ì„œ [(32,16),(8,4)]ë¡œ ë³€ê²½
3. ì¸ì½”ë” ë° ë””ì½”ë”ì—ì„œ FFNì„ ì œê±°

|  | ì‹¤í—˜ëª… | Best MAE | Inference time |
| --- | --- | --- | --- |
| encoder reduction | encoder layer X 2 + [(32,16),(8,4)]Â + ffn ì œê±° | ì•½ 1.78% ì¦ê°€Â (50.49â†’51.39) | 9.19ms ê°ì†ŒÂ (63.95â†’54.76) |

mae ì¸¡ë©´ì—ì„œ **ì„±ëŠ¥í•˜ë½ì´ 1.78% ìˆ˜ì¤€ì´ë©° inference timeì€ 9.19ms** ëŒ€í­ ê°ì†Œí•˜ì˜€ê¸°ì—

maeì™€ inference time ì¸¡ë©´ ëª¨ë‘ì—ì„œ top 3ì˜ ìˆ˜ì¤€ì„ ê¸°ë¡í•˜ì˜€ë‹¤.

**mae : 51.39 inference time 54.76msë¡œ ìµœì¢… ëª¨ë¸ë¡œ ì„ ì • ë˜ì—ˆë‹¤.**

## References
1) [Liu, Chengxin, et al. "Point-query quadtree for crowd counting, localization, and more."](https://arxiv.org/pdf/2308.13814.pdf)
2) [Yanyu Li, Ju Hu, et al. "Rethinking Vision Transformers for MobileNet Size and Speed."](https://arxiv.org/pdf/2212.08059.pdf)
3) [Howard, Andrew, et al. "Searching for mobilenetv3."](https://arxiv.org/pdf/1905.02244.pdf)
4) [Liu, Chengxin, et al. "Point-query quadtree for crowd counting, localization, and more."](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Point-Query_Quadtree_for_ICCV_2023_supplemental.pdf)
5) [Yu, Weihao, et al. "MetaFormer Is Actually What You Need for Vision"](https://arxiv.org/pdf/2308.13814.pdf)
6) [Li, Yanyu, et al. "Efficientformer: Vision transformers at mobilenet speed."](https://arxiv.org/pdf/2206.01191.pdf)


